import typing
import numpy as np
from .dataset import Dataset
from .ops import Op

class Batch:
    '''
    A (mini)batch generated by the batch generator.
    '''

    def __init__(self, data, label,idx):
        '''
        Ctor.
        '''

        self.data = data
        self.label = label
        self.idx = idx

class BatchGenerator:
    '''
    Batch generator.
    Returned batches have the following properties:
      data: numpy array holding batch data of shape (s, SHAPE_OF_DATASET_SAMPLES).
      label: numpy array holding batch labels of shape (s, SHAPE_OF_DATASET_LABELS).
      idx: numpy array with shape (s,) encoding the indices of each sample in the original dataset.
    '''

    def __init__(self, dataset: Dataset, num: int, shuffle: bool, op: Op=None):
        '''
        Ctor.
        Dataset is the dataset to iterate over.
        num is the number of samples per batch. the number in the last batch might be smaller than that.
        shuffle controls whether the sample order should be preserved or not.
        op is an operation to apply to input samples.
        Raises TypeError on invalid argument types.
        Raises ValueError on invalid argument values, such as if num is > len(dataset).
        '''
        if not isinstance(dataset, Dataset):
            raise TypeError("The dataset should be an instance of Dataset class")
        if not isinstance(num, int) or num <= 0:
            raise TypeError("The number of samples per batch should be a positive integer")
        if num > len(dataset):
            raise TypeError("The number of samples per batch should not be bigger than the length of dataset")
        if not isinstance(shuffle, bool):
            raise TypeError("The shuffle argument should be boolean")

        if num > len(dataset):
            raise ValueError("The number of samples per batch should be less than or equal to the dataset size")

        data = dataset.data
        if op:
            data = op(dataset.data)
        
        indexed_elements = [(index,element,label) for index, (element, label) in enumerate(zip(data, dataset.labels))]

        if shuffle:
            np.random.shuffle(indexed_elements)
        
        chunks = [indexed_elements[i:i + num] for i in range(0, len(indexed_elements), num)]

        # Initialize an empty list to store the batches
        batches = []

        # Loop over the chunks
        for chunk in chunks:
            # Initialize empty lists to store the data, labels, and indices
            data, labels, indices = [], [], []
            
            # Loop over the elements in the chunk
            for index, element, label in chunk:
                # Append the flattened element, the label, and the index to their respective lists
                data.append(element.flatten().astype(np.float32))
                labels.append(label.astype(np.int64))
                indices.append(index)
            
            # Create a Batch object from the stacked data, labels, and indices arrays, and append it to the batches list
            batch = Batch(np.stack(data, axis=0), np.stack(labels, axis=0), np.stack(indices, axis=0))
            batches.append(batch)

        # Set the batches attribute of the object to the list of Batch objects
        self.batches = np.array(batches)

    def __len__(self) -> int:
        '''
        Returns the total number of batches the dataset is split into.
            This is identical to the total number of batches yielded every time the __iter__ method is called.
        '''
        
        return int(np.ceil(len(self.dataset) / self.num))


    def __iter__(self) -> typing.Iterable[Batch]:
        '''
        Iterate over the wrapped dataset, returning the data as batches.
        '''

        for i in self.batches:
            yield i
